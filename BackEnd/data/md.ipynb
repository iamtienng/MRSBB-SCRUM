{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(object):\n",
    "    def __init__(self, Y, K, lam = 0.1, Xinit = None, Winit = None, \n",
    "    learning_rate = 0.5, max_iter = 10000, print_every = 100):\n",
    "        self.Y = Y      # represents the utility matrix\n",
    "        self.K = K      # number of features\n",
    "        self.lam = lam  # regularization parameter\n",
    "        self.learning_rate = learning_rate  # for gradient descent\n",
    "        self.max_iter = max_iter            # maximum number of iterations\n",
    "        self.print_every = print_every      # print loss after each a few iters\n",
    "        self.n_users = int(np.max(Y[:, 0])) + 1\n",
    "        self.users_ids = np.unique(np.asarray(Y[:,0].reshape(Y[:,0].shape[0])))\n",
    "        self.n_items = int(np.max(Y[:, 1])) + 1\n",
    "        self.items_ids = np.unique(np.asarray(Y[:,1].reshape(Y[:,1].shape[0])))\n",
    "        self.n_ratings = Y.shape[0]\n",
    "        self.X = np.random.randn(self.n_items, K) if Xinit is None else Xinit\n",
    "        self.W = np.random.randn(K, self.n_users) if Winit is None else Winit\n",
    "        self.b = np.random.randn(self.n_items)  # item biases\n",
    "        self.d = np.random.randn(self.n_users)  # user biases\n",
    "\n",
    "    # return current loss value\n",
    "    def loss(self):\n",
    "        L = 0\n",
    "        for i in range(self.n_ratings):\n",
    "            # user_id, item_id, rating\n",
    "            n, m, rating = int(self.Y[i, 0]), int(self.Y[i, 1]), self.Y[i, 2]\n",
    "            L += 0.5*(self.X[m].dot(self.W[:,n]) + self.b[m] + self.d[n] - rating)**2\n",
    "        L /= self.n_ratings\n",
    "        # regularization, don't ever forget this\n",
    "        return L + 0.5*self.lam*(np.sum(self.X**2) + np.sum(self.W**2))\n",
    "    \n",
    "    def updateXb(self):\n",
    "        for m in self.items_ids:\n",
    "            ids = np.where(self.Y[:, 1] == m)[0] # row indices of items m\n",
    "            user_ids, ratings = self.Y[ids, 0].astype(np.int32), self.Y[ids, 2]\n",
    "            Wm, dm = self.W[:, user_ids], self.d[user_ids]\n",
    "            Wm = Wm.reshape(Wm.shape[0], Wm.shape[1])\n",
    "            for i in range(30): # 30 iteration for each sub problem\n",
    "                xm = self.X[m]\n",
    "                error = Wm.T.dot(xm).reshape(-1,1) + self.b[m] + dm - ratings\n",
    "                grad_xm = Wm.dot(error)/self.n_ratings + (self.lam*xm).reshape(-1,1)\n",
    "                grad_bm = np.sum(error)/self.n_ratings\n",
    "                # gradient descent\n",
    "                self.X[m] -= np.array((self.learning_rate*grad_xm).T)[0]\n",
    "                self.b[m] -= rs.learning_rate*grad_bm\n",
    "\n",
    "    def updateWd(self):\n",
    "        for n in self.users_ids:\n",
    "            # get all items rated by user n, and the corresponding ratings\n",
    "            ids = np.where(self.Y[:, 0] == n)[0]\n",
    "            item_ids, ratings = self.Y[ids, 1].astype(np.int32), self.Y[ids, 2]\n",
    "            Xn, bn = self.X[item_ids], self.b[item_ids]\n",
    "            for i in range(30): # 30 iteration for each sub problem\n",
    "                wn = self.W[:, n]\n",
    "                error = Xn.dot(wn) + bn + self.d[n] - ratings\n",
    "                grad_wn = Xn.T.dot(error)/self.n_ratings + self.lam*wn\n",
    "                grad_dn = np.sum(error)/self.n_ratings\n",
    "                # gradient descent\n",
    "                self.W[:, n] -= np.array(self.learning_rate*grad_wn.reshape(-1))[0]\n",
    "                self.d[n]    -= self.learning_rate*grad_dn\n",
    "\n",
    "    def fit(self):\n",
    "        for it in range(self.max_iter):\n",
    "            self.updateXb()\n",
    "            self.updateWd()\n",
    "            if (it+1) % self.print_every == 0:\n",
    "                rsme_train = self.evaluate_RMSE(self.Y)\n",
    "                # print(\"iter = \",it+1 ,\", loss = \"+self.loss(),\", RMSE train = \",rsme_train)\n",
    "                print(it+1)\n",
    "                print(self.loss())\n",
    "                print(rsme_train)\n",
    "                print(self.evaluate_RMSE(rate_test))\n",
    "\n",
    "    def pred(self, u, i):\n",
    "        # predict the rating of user u for item i\n",
    "        u, i = int(u), int(i)\n",
    "        try:\n",
    "            pred = self.X[i, :].dot(self.W[:, u]) + self.b[i] + self.d[u]\n",
    "        except:\n",
    "            return 0\n",
    "        return max(0, min(5, pred))\n",
    "\n",
    "    def evaluate_RMSE(self, rate_test):\n",
    "        n_tests = rate_test.shape[0]\n",
    "        SE = 0\n",
    "        for n in range(n_tests):\n",
    "            pred = self.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "            SE += (pred - rate_test[n, 2])**2\n",
    "        \n",
    "        RMSE = np.sqrt(SE/n_tests)\n",
    "        return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'item_id', 'rating', 'unix_timestamp']\n",
    "ratings_base = pd.read_csv('ml-100k/ua.base',sep='\\t', names=r_cols)\n",
    "ratings_test = pd.read_csv('ml-100k/ua.test',sep='\\t', names=r_cols)\n",
    "\n",
    "rate_train = np.asmatrix(ratings_base)\n",
    "rate_test = np.asmatrix(ratings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices start from 0\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.9813242949856356\n",
      "0.9576538777513495\n",
      "1.0334281333969082\n",
      "10\n",
      "0.9517149245758885\n",
      "0.927083129976136\n",
      "0.9825093531726448\n",
      "15\n",
      "0.9439737011472505\n",
      "0.9189954890904248\n",
      "0.971302106084739\n",
      "20\n",
      "0.9407339857967102\n",
      "0.9156333436753306\n",
      "0.9675119236760502\n",
      "25\n",
      "0.9390274877027561\n",
      "0.9138814638591751\n",
      "0.9658114878351727\n",
      "30\n",
      "0.938001148320693\n",
      "0.9128350514306869\n",
      "0.9648862591718131\n"
     ]
    }
   ],
   "source": [
    "rs = MF(rate_train, K = 50, lam = .01, print_every = 5, learning_rate = 50,max_iter = 30)\n",
    "rs.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 50)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.W.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.b.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.d.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "1.4112164428286742\n",
      "0.9110216592967477\n",
      "0.9642259343626953\n",
      "100\n",
      "1.4103872466249026\n",
      "0.9101484233572117\n",
      "0.9637777851822874\n",
      "150\n",
      "1.410265329832173\n",
      "0.910013587700607\n",
      "0.9638054119855224\n",
      "200\n",
      "1.4102434456890176\n",
      "0.9099893136200693\n",
      "0.9638450589864979\n"
     ]
    }
   ],
   "source": [
    "rs = MF(rate_train, K = 100, lam = .01, print_every = 50, learning_rate = 50,max_iter = 200)\n",
    "rs.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7728743195945722\n",
      "RMSE for training: 1.9359468008811778\n",
      "RMSE for testing: 2.04553746973497\n",
      "0.7734263726799969\n",
      "RMSE for training: 1.9312344596779494\n",
      "RMSE for testing: 2.0421854817209626\n",
      "0.7739784257654216\n",
      "RMSE for training: 1.9312397368698235\n",
      "RMSE for testing: 2.0421956580385365\n",
      "0.7745304788508462\n",
      "RMSE for training: 1.9311489312762995\n",
      "RMSE for testing: 2.0427715106322997\n",
      "0.775082531936271\n",
      "RMSE for training: 1.9281556733935457\n",
      "RMSE for testing: 2.039251879826298\n",
      "0.7756345850216957\n",
      "RMSE for training: 1.9189605955594236\n",
      "RMSE for testing: 2.0353799373082144\n",
      "0.7761866381071204\n",
      "RMSE for training: 1.9189474026069346\n",
      "RMSE for testing: 2.0361442269588457\n",
      "0.7767386911925451\n",
      "RMSE for training: 1.918974713646788\n",
      "RMSE for testing: 2.035491505930594\n",
      "0.7772907442779697\n",
      "RMSE for training: 1.9189635555394298\n",
      "RMSE for testing: 2.035351045690582\n",
      "0.7778427973633945\n",
      "RMSE for training: 1.9136252267385843\n",
      "RMSE for testing: 2.0322304622469543\n",
      "0.7783948504488192\n",
      "RMSE for training: 1.913058493458399\n",
      "RMSE for testing: 2.031477016711625\n",
      "0.7789469035342439\n",
      "RMSE for training: 1.9131255650903227\n",
      "RMSE for testing: 2.030970809120113\n",
      "0.7794989566196685\n",
      "RMSE for training: 1.9125540455061012\n",
      "RMSE for testing: 2.0287854706605764\n",
      "0.7800510097050932\n",
      "RMSE for training: 1.905892245909491\n",
      "RMSE for testing: 2.0235603980586085\n",
      "0.7806030627905179\n",
      "RMSE for training: 1.905856112822106\n",
      "RMSE for testing: 2.0233594419502796\n",
      "0.7811551158759427\n",
      "RMSE for training: 1.9057833470760541\n",
      "RMSE for testing: 2.0235281050544343\n",
      "0.7817071689613673\n",
      "RMSE for training: 1.9058566938060562\n",
      "RMSE for testing: 2.0228842674963063\n",
      "0.782259222046792\n",
      "RMSE for training: 1.8943552609798804\n",
      "RMSE for testing: 2.018117327157606\n",
      "0.7828112751322167\n",
      "RMSE for training: 1.8942700847903098\n",
      "RMSE for testing: 2.0180414356177665\n",
      "0.7833633282176414\n",
      "RMSE for training: 1.8944124353977574\n",
      "RMSE for testing: 2.0176427912620927\n",
      "0.7839153813030661\n",
      "RMSE for training: 1.8944259845599538\n",
      "RMSE for testing: 2.0182961157886425\n",
      "0.7844674343884908\n",
      "RMSE for training: 1.8943653389118484\n",
      "RMSE for testing: 2.0179941361412213\n",
      "0.7850194874739155\n",
      "RMSE for training: 1.8909749531233693\n",
      "RMSE for testing: 2.0134805131015625\n",
      "0.7855715405593402\n",
      "RMSE for training: 1.8898714062226598\n",
      "RMSE for testing: 2.0101744479469787\n",
      "0.7861235936447649\n",
      "RMSE for training: 1.8881974855966686\n",
      "RMSE for testing: 2.0068229724257094\n",
      "0.7866756467301895\n",
      "RMSE for training: 1.8872305842693096\n",
      "RMSE for testing: 2.003632473568752\n",
      "0.7872276998156142\n",
      "RMSE for training: 1.881291246947774\n",
      "RMSE for testing: 2.000776021521376\n",
      "0.787779752901039\n",
      "RMSE for training: 1.881259097709862\n",
      "RMSE for testing: 2.0008424810133905\n",
      "0.7883318059864637\n",
      "RMSE for training: 1.881325060302899\n",
      "RMSE for testing: 2.000232973835896\n",
      "0.7888838590718884\n",
      "RMSE for training: 1.8795793293958942\n",
      "RMSE for testing: 1.9948930329982626\n",
      "0.789435912157313\n",
      "RMSE for training: 1.8785779562806793\n",
      "RMSE for testing: 1.994119736928445\n",
      "0.7899879652427377\n",
      "RMSE for training: 1.8774600187643726\n",
      "RMSE for testing: 1.9884897229615062\n",
      "0.7905400183281625\n",
      "RMSE for training: 1.8685192055471143\n",
      "RMSE for testing: 1.9865230111563326\n",
      "0.7910920714135872\n",
      "RMSE for training: 1.8686486583228943\n",
      "RMSE for testing: 1.9865840465207303\n",
      "0.7916441244990118\n",
      "RMSE for training: 1.868529781284185\n",
      "RMSE for testing: 1.9863217522037786\n",
      "0.7921961775844365\n",
      "RMSE for training: 1.868544483786952\n",
      "RMSE for testing: 1.986497131405554\n",
      "0.7927482306698612\n",
      "RMSE for training: 1.868490503164219\n",
      "RMSE for testing: 1.9862751989054062\n",
      "0.7933002837552859\n",
      "RMSE for training: 1.8686124993150732\n",
      "RMSE for testing: 1.9866451689793203\n",
      "0.7938523368407105\n",
      "RMSE for training: 1.8668741827762736\n",
      "RMSE for testing: 1.9768006674535517\n",
      "0.7944043899261353\n",
      "RMSE for training: 1.864349936297005\n",
      "RMSE for testing: 1.973903938920587\n",
      "0.79495644301156\n",
      "RMSE for training: 1.8638153213459108\n",
      "RMSE for testing: 1.9707272501566597\n",
      "0.7955084960969847\n",
      "RMSE for training: 1.8611526773304057\n",
      "RMSE for testing: 1.968253004377184\n",
      "0.7960605491824094\n",
      "RMSE for training: 1.8611738786959091\n",
      "RMSE for testing: 1.9686575777465856\n",
      "0.796612602267834\n",
      "RMSE for training: 1.8590043681550357\n",
      "RMSE for testing: 1.9652280688318833\n",
      "0.7971646553532588\n",
      "RMSE for training: 1.857657228376637\n",
      "RMSE for testing: 1.9615692763275199\n",
      "0.7977167084386835\n",
      "RMSE for training: 1.8507626643651838\n",
      "RMSE for testing: 1.949433812639341\n",
      "0.7982687615241082\n",
      "RMSE for training: 1.8507014975560667\n",
      "RMSE for testing: 1.9487195325544049\n",
      "0.7988208146095328\n",
      "RMSE for training: 1.85074359208601\n",
      "RMSE for testing: 1.9490127575632552\n",
      "0.7993728676949575\n",
      "RMSE for training: 1.849893930818718\n",
      "RMSE for testing: 1.9450083180250897\n",
      "0.7999249207803822\n",
      "RMSE for training: 1.8459863569617396\n",
      "RMSE for testing: 1.9394289910554303\n",
      "0.800476973865807\n",
      "RMSE for training: 1.8459229529545325\n",
      "RMSE for testing: 1.9399083462716848\n",
      "0.8010290269512317\n",
      "RMSE for training: 1.8434931126093452\n",
      "RMSE for testing: 1.9287765232516574\n",
      "0.8015810800366563\n",
      "RMSE for training: 1.842162632631843\n",
      "RMSE for testing: 1.9252175206743933\n",
      "0.802133133122081\n",
      "RMSE for training: 1.8397551690512761\n",
      "RMSE for testing: 1.9215660769246383\n",
      "0.8026851862075057\n",
      "RMSE for training: 1.8255789332143795\n",
      "RMSE for testing: 1.9171303013791952\n",
      "0.8032372392929304\n",
      "RMSE for training: 1.825551108963295\n",
      "RMSE for testing: 1.9165141751690493\n",
      "0.8037892923783551\n",
      "RMSE for training: 1.825503520881155\n",
      "RMSE for testing: 1.9163031565511537\n",
      "0.8043413454637798\n",
      "RMSE for training: 1.8254908510599739\n",
      "RMSE for testing: 1.9161219244096235\n",
      "0.8048933985492045\n",
      "RMSE for training: 1.8255008301152502\n",
      "RMSE for testing: 1.916518254115719\n",
      "0.8054454516346292\n",
      "RMSE for training: 1.8255008919512732\n",
      "RMSE for testing: 1.916676542041572\n",
      "0.8059975047200538\n",
      "RMSE for training: 1.8213019740792058\n",
      "RMSE for testing: 1.9130288135359788\n",
      "0.8065495578054785\n",
      "RMSE for training: 1.821205222457009\n",
      "RMSE for testing: 1.912943515428559\n",
      "0.8071016108909033\n",
      "RMSE for training: 1.809353737359615\n",
      "RMSE for testing: 1.9090047537363812\n",
      "0.807653663976328\n",
      "RMSE for training: 1.8093430636143435\n",
      "RMSE for testing: 1.9088001528613774\n",
      "0.8082057170617527\n",
      "RMSE for training: 1.8092676781731223\n",
      "RMSE for testing: 1.9093792388002429\n",
      "0.8087577701471773\n",
      "RMSE for training: 1.8093551079903525\n",
      "RMSE for testing: 1.908841975227242\n",
      "0.809309823232602\n",
      "RMSE for training: 1.8093030029215593\n",
      "RMSE for testing: 1.9089877081535105\n",
      "0.8098618763180268\n",
      "RMSE for training: 1.8087139775009446\n",
      "RMSE for testing: 1.905511850036477\n",
      "0.8104139294034515\n",
      "RMSE for training: 1.802722246618715\n",
      "RMSE for testing: 1.9009927789483745\n",
      "0.8109659824888761\n",
      "RMSE for training: 1.8026768065671048\n",
      "RMSE for testing: 1.9015065582019857\n",
      "0.8115180355743008\n",
      "RMSE for training: 1.8026164245956546\n",
      "RMSE for testing: 1.9007407935871585\n",
      "0.8120700886597255\n",
      "RMSE for training: 1.8007164289159439\n",
      "RMSE for testing: 1.8983148791630018\n",
      "0.8126221417451502\n",
      "RMSE for training: 1.7988221267711653\n",
      "RMSE for testing: 1.8943375175037305\n",
      "0.813174194830575\n",
      "RMSE for training: 1.7979238385400904\n",
      "RMSE for testing: 1.8912355342958505\n",
      "0.8137262479159996\n",
      "RMSE for training: 1.7941345590937738\n",
      "RMSE for testing: 1.884467635741213\n",
      "0.8142783010014243\n",
      "RMSE for training: 1.7939308205837967\n",
      "RMSE for testing: 1.8840402491757668\n",
      "0.814830354086849\n",
      "RMSE for training: 1.7885568149148747\n",
      "RMSE for testing: 1.8809461045301759\n",
      "0.8153824071722737\n",
      "RMSE for training: 1.788544636966626\n",
      "RMSE for testing: 1.8809738154428346\n",
      "0.8159344602576983\n",
      "RMSE for training: 1.7883901703684242\n",
      "RMSE for testing: 1.880781562854671\n",
      "0.816486513343123\n",
      "RMSE for training: 1.7721476166705987\n",
      "RMSE for testing: 1.876752669876923\n",
      "0.8170385664285478\n",
      "RMSE for training: 1.7721811265080594\n",
      "RMSE for testing: 1.8768956568250452\n",
      "0.8175906195139725\n",
      "RMSE for training: 1.7720452044450425\n",
      "RMSE for testing: 1.8768177040557217\n",
      "0.8181426725993971\n",
      "RMSE for training: 1.7721057092773256\n",
      "RMSE for testing: 1.8765858448061654\n",
      "0.8186947256848218\n",
      "RMSE for training: 1.772118932617569\n",
      "RMSE for testing: 1.8771343061089438\n",
      "0.8192467787702465\n",
      "RMSE for training: 1.7720586537928935\n",
      "RMSE for testing: 1.8767309270799322\n",
      "0.8197988318556713\n",
      "RMSE for training: 1.7720809460998446\n",
      "RMSE for testing: 1.8765521757418815\n",
      "0.820350884941096\n",
      "RMSE for training: 1.7710509173096152\n",
      "RMSE for testing: 1.8715668857272987\n",
      "0.8209029380265206\n",
      "RMSE for training: 1.7685403556172885\n",
      "RMSE for testing: 1.8671355626406496\n",
      "0.8214549911119453\n",
      "RMSE for training: 1.7685481292350451\n",
      "RMSE for testing: 1.8667714196643623\n",
      "0.82200704419737\n",
      "RMSE for training: 1.7629928395608447\n",
      "RMSE for testing: 1.8598880308469363\n",
      "0.8225590972827947\n",
      "RMSE for training: 1.7629415356633842\n",
      "RMSE for testing: 1.858766585011994\n",
      "0.8231111503682194\n",
      "RMSE for training: 1.7585460161979165\n",
      "RMSE for testing: 1.8562682810541054\n",
      "0.8236632034536441\n",
      "RMSE for training: 1.758523164279493\n",
      "RMSE for testing: 1.8564670545296718\n",
      "0.8242152565390688\n",
      "RMSE for training: 1.751962431003821\n",
      "RMSE for testing: 1.850019156256227\n",
      "0.8247673096244935\n",
      "RMSE for training: 1.7518312623275152\n",
      "RMSE for testing: 1.8493487219059446\n",
      "0.8253193627099182\n",
      "RMSE for training: 1.751819438689233\n",
      "RMSE for testing: 1.8494577533992973\n",
      "0.8258714157953428\n",
      "RMSE for training: 1.7517647530273361\n",
      "RMSE for testing: 1.8496683073832245\n",
      "0.8264234688807676\n",
      "RMSE for training: 1.7483007740244423\n",
      "RMSE for testing: 1.8411419952096661\n",
      "0.8269755219661923\n",
      "RMSE for training: 1.747681543119272\n",
      "RMSE for testing: 1.8385783509804041\n",
      "0.827527575051617\n",
      "RMSE for training: 1.744462589308818\n",
      "RMSE for testing: 1.833651735454738\n",
      "0.8280796281370416\n",
      "RMSE for training: 1.7418190758827115\n",
      "RMSE for testing: 1.8293353035886832\n",
      "0.8286316812224663\n",
      "RMSE for training: 1.7357377673974632\n",
      "RMSE for testing: 1.8205146096820046\n",
      "0.829183734307891\n",
      "RMSE for training: 1.7354200244906806\n",
      "RMSE for testing: 1.820498221128515\n",
      "0.8297357873933158\n",
      "RMSE for training: 1.735469809547202\n",
      "RMSE for testing: 1.8207022268625843\n",
      "0.8302878404787405\n",
      "RMSE for training: 1.7326398100543186\n",
      "RMSE for testing: 1.8202758922675402\n",
      "0.8308398935641651\n",
      "RMSE for training: 1.7322788763907553\n",
      "RMSE for testing: 1.820072786211618\n",
      "0.8313919466495898\n",
      "RMSE for training: 1.7322483676977807\n",
      "RMSE for testing: 1.8196395778231813\n",
      "0.8319439997350145\n",
      "RMSE for training: 1.732252108105989\n",
      "RMSE for testing: 1.8201605458931673\n",
      "0.8324960528204393\n",
      "RMSE for training: 1.7322335736149812\n",
      "RMSE for testing: 1.8195372863190749\n",
      "0.8330481059058639\n",
      "RMSE for training: 1.7277115862031753\n",
      "RMSE for testing: 1.812702432399376\n",
      "0.8336001589912886\n",
      "RMSE for training: 1.7276010471753507\n",
      "RMSE for testing: 1.8129139811832438\n",
      "0.8341522120767133\n",
      "RMSE for training: 1.7245798333670697\n",
      "RMSE for testing: 1.8063704082511556\n",
      "0.834704265162138\n",
      "RMSE for training: 1.724540915650299\n",
      "RMSE for testing: 1.8069821263731451\n",
      "0.8352563182475626\n",
      "RMSE for training: 1.7209530501347043\n",
      "RMSE for testing: 1.7999295681197922\n",
      "0.8358083713329874\n",
      "RMSE for training: 1.7195152713573476\n",
      "RMSE for testing: 1.7944697479669975\n",
      "0.8363604244184121\n",
      "RMSE for training: 1.7141752876122653\n",
      "RMSE for testing: 1.7919402328460141\n",
      "0.8369124775038368\n",
      "RMSE for training: 1.7141589401817774\n",
      "RMSE for testing: 1.792372828280486\n",
      "0.8374645305892615\n",
      "RMSE for training: 1.7141893149644145\n",
      "RMSE for testing: 1.7918350563942542\n",
      "0.8380165836746861\n",
      "RMSE for training: 1.7140627193927664\n",
      "RMSE for testing: 1.7918734814456958\n",
      "0.8385686367601108\n",
      "RMSE for training: 1.711441473282678\n",
      "RMSE for testing: 1.7838464821290403\n",
      "0.8391206898455356\n",
      "RMSE for training: 1.7052478310899015\n",
      "RMSE for testing: 1.7760349988433506\n",
      "0.8396727429309603\n",
      "RMSE for training: 1.7053547184470297\n",
      "RMSE for testing: 1.7759072777478033\n",
      "0.8402247960163849\n",
      "RMSE for training: 1.7052757042807052\n",
      "RMSE for testing: 1.776019497143992\n",
      "0.8407768491018096\n",
      "RMSE for training: 1.6951641999061964\n",
      "RMSE for testing: 1.76951093079763\n",
      "0.8413289021872343\n",
      "RMSE for training: 1.6949863186658012\n",
      "RMSE for testing: 1.769868040780016\n",
      "0.841880955272659\n",
      "RMSE for training: 1.6950023193944352\n",
      "RMSE for testing: 1.7695235745756415\n",
      "0.8424330083580838\n",
      "RMSE for training: 1.6949879591457\n",
      "RMSE for testing: 1.7692503871793628\n",
      "0.8429850614435084\n",
      "RMSE for training: 1.6950869469206136\n",
      "RMSE for testing: 1.7693484012003828\n",
      "0.8435371145289331\n",
      "RMSE for training: 1.6940025172418098\n",
      "RMSE for testing: 1.764696739442674\n",
      "0.8440891676143578\n",
      "RMSE for training: 1.6875441259780923\n",
      "RMSE for testing: 1.761248069663432\n",
      "0.8446412206997825\n",
      "RMSE for training: 1.6874720160455017\n",
      "RMSE for testing: 1.760931502627003\n",
      "0.8451932737852071\n",
      "RMSE for training: 1.6874919056241122\n",
      "RMSE for testing: 1.7615015819949922\n",
      "0.8457453268706319\n",
      "RMSE for training: 1.6873827071166545\n",
      "RMSE for testing: 1.7614526508908646\n",
      "0.8462973799560566\n",
      "RMSE for training: 1.6855738396948792\n",
      "RMSE for testing: 1.7539587416369882\n",
      "0.8468494330414813\n",
      "RMSE for training: 1.6836474383197426\n",
      "RMSE for testing: 1.7491921787424805\n",
      "0.8474014861269059\n",
      "RMSE for training: 1.6819503659536241\n",
      "RMSE for testing: 1.7432609294996229\n",
      "0.8479535392123306\n",
      "RMSE for training: 1.6772403766652286\n",
      "RMSE for testing: 1.739758319599529\n",
      "0.8485055922977554\n",
      "RMSE for training: 1.6772161814073676\n",
      "RMSE for testing: 1.7397214103772967\n",
      "0.8490576453831801\n",
      "RMSE for training: 1.6770813721658349\n",
      "RMSE for testing: 1.7400747528723985\n",
      "0.8496096984686048\n",
      "RMSE for training: 1.6618819747533444\n",
      "RMSE for testing: 1.7368798486799089\n",
      "0.8501617515540294\n",
      "RMSE for training: 1.6620083065702282\n",
      "RMSE for testing: 1.7371975168284954\n",
      "0.8507138046394541\n",
      "RMSE for training: 1.6619933322062845\n",
      "RMSE for testing: 1.7372577383620509\n",
      "0.8512658577248788\n",
      "RMSE for training: 1.6619251072297576\n",
      "RMSE for testing: 1.7364516461867656\n",
      "0.8518179108103036\n",
      "RMSE for training: 1.6619848805588362\n",
      "RMSE for testing: 1.737372959961594\n",
      "0.8523699638957282\n",
      "RMSE for training: 1.6619704995327143\n",
      "RMSE for testing: 1.7369942778198386\n",
      "0.8529220169811529\n",
      "RMSE for training: 1.6618978488657306\n",
      "RMSE for testing: 1.73699573839644\n",
      "0.8534740700665776\n",
      "RMSE for training: 1.6533607235379033\n",
      "RMSE for testing: 1.731158407311871\n",
      "0.8540261231520023\n",
      "RMSE for training: 1.6532281153660997\n",
      "RMSE for testing: 1.731111094588803\n",
      "0.854578176237427\n",
      "RMSE for training: 1.653300870425872\n",
      "RMSE for testing: 1.7311079622679246\n",
      "0.8551302293228517\n",
      "RMSE for training: 1.6533604039440624\n",
      "RMSE for testing: 1.7309132909239842\n",
      "0.8556822824082764\n",
      "RMSE for training: 1.65348138620296\n",
      "RMSE for testing: 1.731364436902309\n",
      "0.8562343354937011\n",
      "RMSE for training: 1.6481815494723584\n",
      "RMSE for testing: 1.7130905940330061\n",
      "0.8567863885791258\n",
      "RMSE for training: 1.648183107490339\n",
      "RMSE for testing: 1.7130732415644765\n",
      "0.8573384416645504\n",
      "RMSE for training: 1.632787495322213\n",
      "RMSE for testing: 1.704493483056296\n",
      "0.8578904947499751\n",
      "RMSE for training: 1.6327884558427235\n",
      "RMSE for testing: 1.704417575528069\n",
      "0.8584425478353999\n",
      "RMSE for training: 1.6327448534471427\n",
      "RMSE for testing: 1.7047332727057036\n",
      "0.8589946009208246\n",
      "RMSE for training: 1.632852423712507\n",
      "RMSE for testing: 1.7043734993262396\n",
      "0.8595466540062492\n",
      "RMSE for training: 1.6327817805082054\n",
      "RMSE for testing: 1.7042395169788604\n",
      "0.8600987070916739\n",
      "RMSE for training: 1.6327735886245256\n",
      "RMSE for testing: 1.7047195220689484\n",
      "0.8606507601770986\n",
      "RMSE for training: 1.632904889940464\n",
      "RMSE for testing: 1.7049824306452126\n",
      "0.8612028132625233\n",
      "RMSE for training: 1.6226166304833896\n",
      "RMSE for testing: 1.70103526884655\n",
      "0.8617548663479481\n",
      "RMSE for training: 1.6226387411023846\n",
      "RMSE for testing: 1.7007723388570701\n",
      "0.8623069194333727\n",
      "RMSE for training: 1.6226684613159243\n",
      "RMSE for testing: 1.7003667730661376\n",
      "0.8628589725187974\n",
      "RMSE for training: 1.6227352891901634\n",
      "RMSE for testing: 1.7007003865635608\n",
      "0.8634110256042221\n",
      "RMSE for training: 1.6225881072994024\n",
      "RMSE for testing: 1.7008869918325733\n",
      "0.8639630786896468\n",
      "RMSE for training: 1.6165956569463158\n",
      "RMSE for testing: 1.6969252253247518\n",
      "0.8645151317750714\n",
      "RMSE for training: 1.6166494823452824\n",
      "RMSE for testing: 1.6969502495896012\n",
      "0.8650671848604962\n",
      "RMSE for training: 1.6166054906241911\n",
      "RMSE for testing: 1.6969293590789243\n",
      "0.8656192379459209\n",
      "RMSE for training: 1.6066799574021264\n",
      "RMSE for testing: 1.6921186427917763\n",
      "0.8661712910313456\n",
      "RMSE for training: 1.6066236338281696\n",
      "RMSE for testing: 1.691714495470741\n",
      "0.8667233441167703\n",
      "RMSE for training: 1.606624733956181\n",
      "RMSE for testing: 1.6919593794576535\n",
      "0.8672753972021949\n",
      "RMSE for training: 1.605749119963821\n",
      "RMSE for testing: 1.6869445302369663\n",
      "0.8678274502876197\n",
      "RMSE for training: 1.6033148826506778\n",
      "RMSE for testing: 1.66652500002201\n",
      "0.8683795033730444\n",
      "RMSE for training: 1.5933948804175049\n",
      "RMSE for testing: 1.6570681009023551\n",
      "0.8689315564584691\n",
      "RMSE for training: 1.5934725602479927\n",
      "RMSE for testing: 1.6564627650133759\n",
      "0.8694836095438937\n",
      "RMSE for training: 1.5932958371835062\n",
      "RMSE for testing: 1.6569241347297572\n",
      "0.8700356626293184\n",
      "RMSE for training: 1.5933389906516526\n",
      "RMSE for testing: 1.6572693011007036\n",
      "0.8705877157147431\n",
      "RMSE for training: 1.5916584557555986\n",
      "RMSE for testing: 1.6482616011125817\n",
      "0.8711397688001679\n",
      "RMSE for training: 1.5897849099109964\n",
      "RMSE for testing: 1.635605111841744\n",
      "0.8716918218855925\n",
      "RMSE for training: 1.5864266904242654\n",
      "RMSE for testing: 1.6289384020517201\n",
      "0.8722438749710172\n",
      "RMSE for training: 1.5759145416319038\n",
      "RMSE for testing: 1.6209609369454303\n",
      "0.8727959280564419\n",
      "RMSE for training: 1.5759035827684182\n",
      "RMSE for testing: 1.621138350570168\n",
      "0.8733479811418666\n",
      "RMSE for training: 1.5758085402146396\n",
      "RMSE for testing: 1.6201336814131677\n",
      "0.8739000342272913\n",
      "RMSE for training: 1.5757343476773973\n",
      "RMSE for testing: 1.617846998202749\n",
      "0.874452087312716\n",
      "RMSE for training: 1.5693665948312951\n",
      "RMSE for testing: 1.6152719668150324\n",
      "0.8750041403981407\n",
      "RMSE for training: 1.5694397847308876\n",
      "RMSE for testing: 1.614866897186424\n",
      "0.8755561934835654\n",
      "RMSE for training: 1.5639490387042658\n",
      "RMSE for testing: 1.608639647990969\n",
      "0.8761082465689901\n",
      "RMSE for training: 1.5641589982537196\n",
      "RMSE for testing: 1.6089707532582123\n",
      "0.8766602996544147\n",
      "RMSE for training: 1.563387380506422\n",
      "RMSE for testing: 1.6053423404445122\n",
      "0.8772123527398394\n",
      "RMSE for training: 1.5604664146189406\n",
      "RMSE for testing: 1.6013927292756187\n",
      "0.8777644058252642\n",
      "RMSE for training: 1.5603057863569072\n",
      "RMSE for testing: 1.600851647033033\n",
      "0.8783164589106889\n",
      "RMSE for training: 1.5577928552062859\n",
      "RMSE for testing: 1.5971936504795803\n",
      "0.8788685119961136\n",
      "RMSE for training: 1.55276106622533\n",
      "RMSE for testing: 1.592502373101243\n",
      "0.8794205650815382\n",
      "RMSE for training: 1.552845420102962\n",
      "RMSE for testing: 1.592375966382483\n",
      "0.8799726181669629\n",
      "RMSE for training: 1.550066871786502\n",
      "RMSE for testing: 1.5888246980289387\n",
      "0.8805246712523876\n",
      "RMSE for training: 1.540590836676532\n",
      "RMSE for testing: 1.5822544545034685\n",
      "0.8810767243378124\n",
      "RMSE for training: 1.5405202633025854\n",
      "RMSE for testing: 1.5823913713949593\n",
      "0.881628777423237\n",
      "RMSE for training: 1.5405978792291082\n",
      "RMSE for testing: 1.5833428647740526\n",
      "0.8821808305086617\n",
      "RMSE for training: 1.540573735653022\n",
      "RMSE for testing: 1.582478320584147\n",
      "0.8827328835940864\n",
      "RMSE for training: 1.54049500830391\n",
      "RMSE for testing: 1.5827549200126418\n",
      "0.8832849366795111\n",
      "RMSE for training: 1.5380281335002002\n",
      "RMSE for testing: 1.5769118906936068\n",
      "0.8838369897649357\n",
      "RMSE for training: 1.5324194489579075\n",
      "RMSE for testing: 1.5708589113249014\n",
      "0.8843890428503605\n",
      "RMSE for training: 1.5324157399086906\n",
      "RMSE for testing: 1.5713895017546626\n",
      "0.8849410959357852\n",
      "RMSE for training: 1.5302026077302742\n",
      "RMSE for testing: 1.5660968025115667\n",
      "0.8854931490212099\n",
      "RMSE for training: 1.5288037101361922\n",
      "RMSE for testing: 1.561854878821023\n",
      "0.8860452021066346\n",
      "RMSE for training: 1.5238956111843907\n",
      "RMSE for testing: 1.555418820284716\n",
      "0.8865972551920592\n",
      "RMSE for training: 1.5221602538501606\n",
      "RMSE for testing: 1.5533727484556457\n",
      "0.887149308277484\n",
      "RMSE for training: 1.5106127764510724\n",
      "RMSE for testing: 1.546439466680203\n",
      "0.8877013613629087\n",
      "RMSE for training: 1.5104408027514165\n",
      "RMSE for testing: 1.5467212349725117\n",
      "0.8882534144483334\n",
      "RMSE for training: 1.5104289405717644\n",
      "RMSE for testing: 1.5469163098912155\n",
      "0.888805467533758\n",
      "RMSE for training: 1.5104174845674838\n",
      "RMSE for testing: 1.546388261752028\n",
      "0.8893575206191827\n",
      "RMSE for training: 1.5082077682215493\n",
      "RMSE for testing: 1.538193404491432\n",
      "0.8899095737046074\n",
      "RMSE for training: 1.5030021767810238\n",
      "RMSE for testing: 1.5351917689448622\n",
      "0.8904616267900322\n",
      "RMSE for training: 1.5030645431671321\n",
      "RMSE for testing: 1.534786624938349\n",
      "0.8910136798754569\n",
      "RMSE for training: 1.5031027006244995\n",
      "RMSE for testing: 1.535035590221929\n",
      "0.8915657329608815\n",
      "RMSE for training: 1.5031084505262924\n",
      "RMSE for testing: 1.5357603111758424\n",
      "0.8921177860463062\n",
      "RMSE for training: 1.4995582340503435\n",
      "RMSE for testing: 1.5317423096545635\n",
      "0.8926698391317309\n",
      "RMSE for training: 1.4780954234857573\n",
      "RMSE for testing: 1.5255998847417793\n",
      "0.8932218922171556\n",
      "RMSE for training: 1.4778645707930433\n",
      "RMSE for testing: 1.525195095019895\n",
      "0.8937739453025803\n",
      "RMSE for training: 1.4778712741804283\n",
      "RMSE for testing: 1.5256142978069471\n",
      "0.894325998388005\n",
      "RMSE for training: 1.4779290810739492\n",
      "RMSE for testing: 1.5254547900333058\n",
      "0.8948780514734297\n",
      "RMSE for training: 1.4779094586848733\n",
      "RMSE for testing: 1.5250234271028542\n",
      "0.8954301045588544\n",
      "RMSE for training: 1.4778129634353663\n",
      "RMSE for testing: 1.5250481575577095\n",
      "0.895982157644279\n",
      "RMSE for training: 1.4778507067994604\n",
      "RMSE for testing: 1.5250603756075691\n",
      "0.8965342107297037\n",
      "RMSE for training: 1.4777203288224199\n",
      "RMSE for testing: 1.5258078183539445\n",
      "0.8970862638151285\n",
      "RMSE for training: 1.473005830414233\n",
      "RMSE for testing: 1.5232440367225204\n",
      "0.8976383169005532\n",
      "RMSE for training: 1.4729630784214196\n",
      "RMSE for testing: 1.5230252793558843\n",
      "0.8981903699859779\n",
      "RMSE for training: 1.47286879202589\n",
      "RMSE for testing: 1.5234315227112047\n",
      "0.8987424230714025\n",
      "RMSE for training: 1.4632585194781023\n",
      "RMSE for testing: 1.5165051731468757\n",
      "0.8992944761568272\n",
      "RMSE for training: 1.4630803103804746\n",
      "RMSE for testing: 1.5165427335187929\n",
      "0.899846529242252\n",
      "RMSE for training: 1.463160285270768\n",
      "RMSE for testing: 1.5164049821917025\n",
      "0.9003985823276767\n",
      "RMSE for training: 1.4587357031423125\n",
      "RMSE for testing: 1.5017725297042208\n",
      "0.9009506354131013\n",
      "RMSE for training: 1.4495577246507765\n",
      "RMSE for testing: 1.4970835305800223\n",
      "0.901502688498526\n",
      "RMSE for training: 1.449496176449243\n",
      "RMSE for testing: 1.4967492752479818\n",
      "0.9020547415839507\n",
      "RMSE for training: 1.4495821235643003\n",
      "RMSE for testing: 1.496347448552651\n",
      "0.9026067946693754\n",
      "RMSE for training: 1.4496043155099603\n",
      "RMSE for testing: 1.4974497746721216\n",
      "0.9031588477548002\n",
      "RMSE for training: 1.4476524397004653\n",
      "RMSE for testing: 1.4916957414567185\n",
      "0.9037109008402248\n",
      "RMSE for training: 1.438347046623308\n",
      "RMSE for testing: 1.4845126433752411\n",
      "0.9042629539256495\n",
      "RMSE for training: 1.4382141200985719\n",
      "RMSE for testing: 1.4850473689216048\n",
      "0.9048150070110742\n",
      "RMSE for training: 1.4382415188835396\n",
      "RMSE for testing: 1.485263667450248\n",
      "0.9053670600964989\n",
      "RMSE for training: 1.4383248283037462\n",
      "RMSE for testing: 1.4844851121819747\n",
      "0.9059191131819235\n",
      "RMSE for training: 1.437701812594816\n",
      "RMSE for testing: 1.4810789261361987\n",
      "0.9064711662673482\n",
      "RMSE for training: 1.4342883793880308\n",
      "RMSE for testing: 1.4624222485605247\n",
      "0.907023219352773\n",
      "RMSE for training: 1.4316649883386459\n",
      "RMSE for testing: 1.4578014471710306\n",
      "0.9075752724381977\n",
      "RMSE for training: 1.4298289769225891\n",
      "RMSE for testing: 1.451424787147655\n",
      "0.9081273255236223\n",
      "RMSE for training: 1.418410967299477\n",
      "RMSE for testing: 1.4459931136391393\n",
      "0.908679378609047\n",
      "RMSE for training: 1.4184032713105899\n",
      "RMSE for testing: 1.4455510733158992\n",
      "0.9092314316944717\n",
      "RMSE for training: 1.4184063929449466\n",
      "RMSE for testing: 1.4451626718355572\n",
      "0.9097834847798965\n",
      "RMSE for training: 1.4146522877727292\n",
      "RMSE for testing: 1.4403449805717037\n",
      "0.9103355378653212\n",
      "RMSE for training: 1.4144994004778253\n",
      "RMSE for testing: 1.4401348910639111\n",
      "0.9108875909507458\n",
      "RMSE for training: 1.3981661877917348\n",
      "RMSE for testing: 1.4352414482890403\n",
      "0.9114396440361705\n",
      "RMSE for training: 1.3978837427133508\n",
      "RMSE for testing: 1.4339309645558251\n",
      "0.9119916971215952\n",
      "RMSE for training: 1.3979337166573391\n",
      "RMSE for testing: 1.4343047682028267\n",
      "0.9125437502070199\n",
      "RMSE for training: 1.3978224453364925\n",
      "RMSE for testing: 1.4342010023165104\n",
      "0.9130958032924446\n",
      "RMSE for training: 1.3979922206927524\n",
      "RMSE for testing: 1.434428194703818\n",
      "0.9136478563778693\n",
      "RMSE for training: 1.3978499118684895\n",
      "RMSE for testing: 1.4348960322426976\n",
      "0.914199909463294\n",
      "RMSE for training: 1.3967124007845457\n",
      "RMSE for testing: 1.4325424928212713\n",
      "0.9147519625487187\n",
      "RMSE for training: 1.3902870779406031\n",
      "RMSE for testing: 1.4220619480052767\n",
      "0.9153040156341434\n",
      "RMSE for training: 1.3900728277439482\n",
      "RMSE for testing: 1.4233894484829708\n",
      "0.915856068719568\n",
      "RMSE for training: 1.3829375186540218\n",
      "RMSE for testing: 1.420863440337729\n",
      "0.9164081218049928\n",
      "RMSE for training: 1.3827682072361502\n",
      "RMSE for testing: 1.420781191107594\n",
      "0.9169601748904175\n",
      "RMSE for training: 1.3828547273697755\n",
      "RMSE for testing: 1.4210925189647468\n",
      "0.9175122279758422\n",
      "RMSE for training: 1.3829251104878666\n",
      "RMSE for testing: 1.4207490462620291\n",
      "0.9180642810612668\n",
      "RMSE for training: 1.368739133905213\n",
      "RMSE for testing: 1.4150101631158705\n",
      "0.9186163341466915\n",
      "RMSE for training: 1.3686464880024294\n",
      "RMSE for testing: 1.4146679448130124\n",
      "0.9191683872321162\n",
      "RMSE for training: 1.3685078104952375\n",
      "RMSE for testing: 1.4155179577284416\n",
      "0.919720440317541\n",
      "RMSE for training: 1.3685860104120509\n",
      "RMSE for testing: 1.4145089146935885\n",
      "0.9202724934029656\n",
      "RMSE for training: 1.3685286231056455\n",
      "RMSE for testing: 1.414929005712428\n",
      "0.9208245464883903\n",
      "RMSE for training: 1.368607433994595\n",
      "RMSE for testing: 1.4146538548321506\n",
      "0.921376599573815\n",
      "RMSE for training: 1.3634171192788487\n",
      "RMSE for testing: 1.4107773401928123\n",
      "0.9219286526592397\n",
      "RMSE for training: 1.3634944694760813\n",
      "RMSE for testing: 1.4098339903724217\n",
      "0.9224807057446645\n",
      "RMSE for training: 1.3608125726334253\n",
      "RMSE for testing: 1.406180519796488\n",
      "0.9230327588300891\n",
      "RMSE for training: 1.3587382337432539\n",
      "RMSE for testing: 1.3960934255924766\n",
      "0.9235848119155138\n",
      "RMSE for training: 1.353214858762947\n",
      "RMSE for testing: 1.3882761308558533\n",
      "0.9241368650009385\n",
      "RMSE for training: 1.3481702441356498\n",
      "RMSE for testing: 1.3759732976769392\n",
      "0.9246889180863632\n",
      "RMSE for training: 1.348166051680197\n",
      "RMSE for testing: 1.3763274177462737\n",
      "0.9252409711717878\n",
      "RMSE for training: 1.3426759088487954\n",
      "RMSE for testing: 1.370389334891306\n",
      "0.9257930242572125\n",
      "RMSE for training: 1.3427789879348997\n",
      "RMSE for testing: 1.370633849308275\n",
      "0.9263450773426373\n",
      "RMSE for training: 1.3417898466672242\n",
      "RMSE for testing: 1.3645823040331009\n",
      "0.926897130428062\n",
      "RMSE for training: 1.3238887217509103\n",
      "RMSE for testing: 1.3604627938195155\n",
      "0.9274491835134867\n",
      "RMSE for training: 1.3238268394634731\n",
      "RMSE for testing: 1.3592733102456722\n",
      "0.9280012365989113\n",
      "RMSE for training: 1.3239516078764766\n",
      "RMSE for testing: 1.35927852701896\n",
      "0.928553289684336\n",
      "RMSE for training: 1.3237557102314501\n",
      "RMSE for testing: 1.3608458485158599\n",
      "0.9291053427697608\n",
      "RMSE for training: 1.3238425601600141\n",
      "RMSE for testing: 1.3606278333459\n",
      "0.9296573958551855\n",
      "RMSE for training: 1.3238924574254758\n",
      "RMSE for testing: 1.3608281255869912\n",
      "0.9302094489406101\n",
      "RMSE for training: 1.3237915033191614\n",
      "RMSE for testing: 1.3608147615115347\n",
      "0.9307615020260348\n",
      "RMSE for training: 1.3120977137143135\n",
      "RMSE for testing: 1.3552339190256695\n",
      "0.9313135551114595\n",
      "RMSE for training: 1.3121175578408892\n",
      "RMSE for testing: 1.354198667417916\n",
      "0.9318656081968842\n",
      "RMSE for training: 1.3120102493823413\n",
      "RMSE for testing: 1.3551112358735111\n",
      "0.9324176612823089\n",
      "RMSE for training: 1.3119394156380084\n",
      "RMSE for testing: 1.3547328452974015\n",
      "0.9329697143677336\n",
      "RMSE for training: 1.311994375458062\n",
      "RMSE for testing: 1.3551763411237177\n",
      "0.9335217674531583\n",
      "RMSE for training: 1.3032107169895057\n",
      "RMSE for testing: 1.3462240063867186\n",
      "0.934073820538583\n",
      "RMSE for training: 1.3032392886824864\n",
      "RMSE for testing: 1.3465886238851457\n",
      "0.9346258736240077\n",
      "RMSE for training: 1.2864844989554707\n",
      "RMSE for testing: 1.3401594447460683\n",
      "0.9351779267094323\n",
      "RMSE for training: 1.2863500090728999\n",
      "RMSE for testing: 1.340024021798229\n",
      "0.9357299797948571\n",
      "RMSE for training: 1.286166233471799\n",
      "RMSE for testing: 1.3397195746689354\n",
      "0.9362820328802818\n",
      "RMSE for training: 1.2862399902575266\n",
      "RMSE for testing: 1.3404283858529384\n",
      "0.9368340859657065\n",
      "RMSE for training: 1.2863265406358178\n",
      "RMSE for testing: 1.3401836654646566\n",
      "0.9373861390511311\n",
      "RMSE for training: 1.2842420953262068\n",
      "RMSE for testing: 1.333989238234981\n",
      "0.9379381921365558\n",
      "RMSE for training: 1.2800199330854074\n",
      "RMSE for testing: 1.3274680464581083\n",
      "0.9384902452219805\n",
      "RMSE for training: 1.279864445117398\n",
      "RMSE for testing: 1.3275584140372338\n",
      "0.9390422983074053\n",
      "RMSE for training: 1.2684470857318728\n",
      "RMSE for testing: 1.3243228782256504\n",
      "0.93959435139283\n",
      "RMSE for training: 1.2682318570173001\n",
      "RMSE for testing: 1.3244156947077401\n",
      "0.9401464044782546\n",
      "RMSE for training: 1.2683385862121612\n",
      "RMSE for testing: 1.3243071116862912\n",
      "0.9406984575636793\n",
      "RMSE for training: 1.268432817845547\n",
      "RMSE for testing: 1.323971711248001\n",
      "0.941250510649104\n",
      "RMSE for training: 1.2683975359844146\n",
      "RMSE for testing: 1.3242086837692666\n",
      "0.9418025637345288\n",
      "RMSE for training: 1.257743164237027\n",
      "RMSE for testing: 1.3183566983022552\n",
      "0.9423546168199534\n",
      "RMSE for training: 1.2575706303535774\n",
      "RMSE for testing: 1.3174437419777465\n",
      "0.9429066699053781\n",
      "RMSE for training: 1.2577425319996103\n",
      "RMSE for testing: 1.3185649844826512\n",
      "0.9434587229908028\n",
      "RMSE for training: 1.2404720254416477\n",
      "RMSE for testing: 1.304565934253727\n",
      "0.9440107760762275\n",
      "RMSE for training: 1.2403710780493402\n",
      "RMSE for testing: 1.303960722594892\n",
      "0.9445628291616522\n",
      "RMSE for training: 1.240230723099636\n",
      "RMSE for testing: 1.3048583686775017\n",
      "0.9451148822470768\n",
      "RMSE for training: 1.2403218578332609\n",
      "RMSE for testing: 1.3057100157569255\n",
      "0.9456669353325016\n",
      "RMSE for training: 1.2400284067453444\n",
      "RMSE for testing: 1.3047207212216727\n",
      "0.9462189884179263\n",
      "RMSE for training: 1.2402750243522378\n",
      "RMSE for testing: 1.304655005921891\n",
      "0.946771041503351\n",
      "RMSE for training: 1.2327512672676453\n",
      "RMSE for testing: 1.299481893425596\n",
      "0.9473230945887756\n",
      "RMSE for training: 1.2327049680663282\n",
      "RMSE for testing: 1.2994861746060145\n",
      "0.9478751476742003\n",
      "RMSE for training: 1.2303352346722185\n",
      "RMSE for testing: 1.2941631303223415\n",
      "0.948427200759625\n",
      "RMSE for training: 1.213689420380333\n",
      "RMSE for testing: 1.2884942598263158\n",
      "0.9489792538450498\n",
      "RMSE for training: 1.2135269124365087\n",
      "RMSE for testing: 1.2868043570858014\n",
      "0.9495313069304744\n",
      "RMSE for training: 1.213646680177325\n",
      "RMSE for testing: 1.287023565363324\n",
      "0.9500833600158991\n",
      "RMSE for training: 1.2137777426066316\n",
      "RMSE for testing: 1.2878086270906361\n",
      "0.9506354131013238\n",
      "RMSE for training: 1.2136289194922005\n",
      "RMSE for testing: 1.2878852902882418\n",
      "0.9511874661867485\n",
      "RMSE for training: 1.211276702116233\n",
      "RMSE for testing: 1.2817368106019293\n",
      "0.9517395192721733\n",
      "RMSE for training: 1.196830328962132\n",
      "RMSE for testing: 1.2759381811487436\n",
      "0.9522915723575979\n",
      "RMSE for training: 1.1968808122699117\n",
      "RMSE for testing: 1.276478809874186\n",
      "0.9528436254430226\n",
      "RMSE for training: 1.1967752943462786\n",
      "RMSE for testing: 1.2759113615630187\n",
      "0.9533956785284473\n",
      "RMSE for training: 1.1967922797029376\n",
      "RMSE for testing: 1.2757170338343917\n",
      "0.953947731613872\n",
      "RMSE for training: 1.180941321832495\n",
      "RMSE for testing: 1.2661898273166705\n",
      "0.9544997846992966\n",
      "RMSE for training: 1.1808792085171684\n",
      "RMSE for testing: 1.2665725150079785\n",
      "0.9550518377847214\n",
      "RMSE for training: 1.1810074868188631\n",
      "RMSE for testing: 1.2659467382656757\n",
      "0.9556038908701461\n",
      "RMSE for training: 1.1807852784165827\n",
      "RMSE for testing: 1.2666072861121997\n",
      "0.9561559439555708\n",
      "RMSE for training: 1.1808162936363207\n",
      "RMSE for testing: 1.2659545977740898\n",
      "0.9567079970409955\n",
      "RMSE for training: 1.1808551759967385\n",
      "RMSE for testing: 1.2667875903033614\n",
      "0.9572600501264201\n",
      "RMSE for training: 1.1807078081533697\n",
      "RMSE for testing: 1.2665662114056433\n",
      "0.9578121032118448\n",
      "RMSE for training: 1.169978441970861\n",
      "RMSE for testing: 1.2605101060484252\n",
      "0.9583641562972696\n",
      "RMSE for training: 1.168214763944651\n",
      "RMSE for testing: 1.2584096346497937\n",
      "0.9589162093826943\n",
      "RMSE for training: 1.1678583007044008\n",
      "RMSE for testing: 1.2576981219954162\n",
      "0.9594682624681189\n",
      "RMSE for training: 1.1682130051918291\n",
      "RMSE for testing: 1.2583133321307893\n",
      "0.9600203155535436\n",
      "RMSE for training: 1.159527552569725\n",
      "RMSE for testing: 1.2465807791595052\n",
      "0.9605723686389683\n",
      "RMSE for training: 1.159585872598057\n",
      "RMSE for testing: 1.2461653710510348\n",
      "0.961124421724393\n",
      "RMSE for training: 1.1596490038884064\n",
      "RMSE for testing: 1.2467899551468447\n",
      "0.9616764748098177\n",
      "RMSE for training: 1.158386811291343\n",
      "RMSE for testing: 1.2432635026944359\n",
      "0.9622285278952424\n",
      "RMSE for training: 1.1502385210908073\n",
      "RMSE for testing: 1.2377999460822127\n",
      "0.9627805809806671\n",
      "RMSE for training: 1.1504976525642625\n",
      "RMSE for testing: 1.238015340040557\n",
      "0.9633326340660918\n",
      "RMSE for training: 1.1481035897595449\n",
      "RMSE for testing: 1.231549673621928\n",
      "0.9638846871515165\n",
      "RMSE for training: 1.1388615714834043\n",
      "RMSE for testing: 1.225955434492556\n",
      "0.9644367402369411\n",
      "RMSE for training: 1.138771414908151\n",
      "RMSE for testing: 1.2245458803892975\n",
      "0.9649887933223659\n",
      "RMSE for training: 1.1361962589891692\n",
      "RMSE for testing: 1.2191594614069197\n",
      "0.9655408464077906\n",
      "RMSE for training: 1.1325111483164045\n",
      "RMSE for testing: 1.2088395416869424\n",
      "0.9660928994932153\n",
      "RMSE for training: 1.1186066528399936\n",
      "RMSE for testing: 1.2005740645106473\n",
      "0.9666449525786399\n",
      "RMSE for training: 1.118414647814383\n",
      "RMSE for testing: 1.2012612783920718\n",
      "0.9671970056640646\n",
      "RMSE for training: 1.1182199101769204\n",
      "RMSE for testing: 1.2011660991095665\n",
      "0.9677490587494894\n",
      "RMSE for training: 1.1142229903250733\n",
      "RMSE for testing: 1.1968371693400923\n",
      "0.9683011118349141\n",
      "RMSE for training: 1.110384373180143\n",
      "RMSE for testing: 1.1806116727340505\n",
      "0.9688531649203388\n",
      "RMSE for training: 1.1042539603405137\n",
      "RMSE for testing: 1.1730765424095992\n",
      "0.9694052180057634\n",
      "RMSE for training: 1.1040117110606154\n",
      "RMSE for testing: 1.1733997736953337\n",
      "0.9699572710911881\n",
      "RMSE for training: 1.1009584862406108\n",
      "RMSE for testing: 1.1663355142067855\n",
      "0.9705093241766128\n",
      "RMSE for training: 1.0932692202329413\n",
      "RMSE for testing: 1.1618731575419092\n",
      "0.9710613772620376\n",
      "RMSE for training: 1.0931819997950076\n",
      "RMSE for testing: 1.1610268015176146\n",
      "0.9716134303474622\n",
      "RMSE for training: 1.0931617657274422\n",
      "RMSE for testing: 1.1609308087207832\n",
      "0.9721654834328869\n",
      "RMSE for training: 1.073694471522565\n",
      "RMSE for testing: 1.1495141148810375\n",
      "0.9727175365183116\n",
      "RMSE for training: 1.073517906486517\n",
      "RMSE for testing: 1.1496218848724487\n",
      "0.9732695896037363\n",
      "RMSE for training: 1.0732658835501672\n",
      "RMSE for testing: 1.1485154904921635\n",
      "0.9738216426891609\n",
      "RMSE for training: 1.0733520306574431\n",
      "RMSE for testing: 1.1496572447536773\n",
      "0.9743736957745857\n",
      "RMSE for training: 1.0732891396583841\n",
      "RMSE for testing: 1.14943705788044\n",
      "0.9749257488600104\n",
      "RMSE for training: 1.0732106325860808\n",
      "RMSE for testing: 1.1488792761103301\n",
      "0.9754778019454351\n",
      "RMSE for training: 1.07185650742071\n",
      "RMSE for testing: 1.1424749705767756\n",
      "0.9760298550308598\n",
      "RMSE for training: 1.0668221454251976\n",
      "RMSE for testing: 1.136958464769969\n",
      "0.9765819081162844\n",
      "RMSE for training: 1.0667716933546307\n",
      "RMSE for testing: 1.1366797916861213\n",
      "0.9771339612017091\n",
      "RMSE for training: 1.0532012878513843\n",
      "RMSE for testing: 1.1309728805926837\n",
      "0.9776860142871339\n",
      "RMSE for training: 1.0535539297760286\n",
      "RMSE for testing: 1.1297333848177649\n",
      "0.9782380673725586\n",
      "RMSE for training: 1.0532016309674368\n",
      "RMSE for testing: 1.1305131216502626\n",
      "0.9787901204579832\n",
      "RMSE for training: 1.0533142894189564\n",
      "RMSE for testing: 1.130731713183463\n",
      "0.9793421735434079\n",
      "RMSE for training: 1.0466966632144348\n",
      "RMSE for testing: 1.121326195920439\n",
      "0.9798942266288326\n",
      "RMSE for training: 1.0467643150267336\n",
      "RMSE for testing: 1.1207087460069876\n",
      "0.9804462797142574\n",
      "RMSE for training: 1.0394944935994563\n",
      "RMSE for testing: 1.1150142594424262\n",
      "0.9809983327996821\n",
      "RMSE for training: 1.0396038762034143\n",
      "RMSE for testing: 1.1155860641283413\n",
      "0.9815503858851067\n",
      "RMSE for training: 1.0336050710467495\n",
      "RMSE for testing: 1.108080587478744\n",
      "0.9821024389705314\n",
      "RMSE for training: 1.0336669526750313\n",
      "RMSE for testing: 1.1084074328115854\n",
      "0.9826544920559561\n",
      "RMSE for training: 1.0279935783865821\n",
      "RMSE for testing: 1.1016860195077103\n",
      "0.9832065451413808\n",
      "RMSE for training: 1.0269203521317478\n",
      "RMSE for testing: 1.0947337158168677\n",
      "0.9837585982268054\n",
      "RMSE for training: 1.0185813998114868\n",
      "RMSE for testing: 1.0824822190859167\n",
      "0.9843106513122302\n",
      "RMSE for training: 1.0185276387997222\n",
      "RMSE for testing: 1.081921149769428\n",
      "0.9848627043976549\n",
      "RMSE for training: 1.0132098159911196\n",
      "RMSE for testing: 1.0644001898796798\n",
      "0.9854147574830796\n",
      "RMSE for training: 1.0105011374853263\n",
      "RMSE for testing: 1.0605837605702584\n",
      "0.9859668105685042\n",
      "RMSE for training: 1.006212374273229\n",
      "RMSE for testing: 1.054749436608781\n",
      "0.9865188636539289\n",
      "RMSE for training: 0.9859481929843081\n",
      "RMSE for testing: 1.0478207414949234\n",
      "0.9870709167393537\n",
      "RMSE for training: 0.9855915160223626\n",
      "RMSE for testing: 1.0475456671646524\n",
      "0.9876229698247784\n",
      "RMSE for training: 0.9856768102901182\n",
      "RMSE for testing: 1.0464922018633642\n",
      "0.9881750229102031\n",
      "RMSE for training: 0.9856058032221613\n",
      "RMSE for testing: 1.0476953847265675\n",
      "0.9887270759956277\n",
      "RMSE for training: 0.9855536964673764\n",
      "RMSE for testing: 1.0470694602321122\n",
      "0.9892791290810524\n",
      "RMSE for training: 0.9785938801272026\n",
      "RMSE for testing: 1.039590499575163\n",
      "0.9898311821664771\n",
      "RMSE for training: 0.9784059438132429\n",
      "RMSE for testing: 1.039994640018444\n",
      "0.9903832352519019\n",
      "RMSE for training: 0.9783716363152246\n",
      "RMSE for testing: 1.0401724145835567\n",
      "0.9909352883373265\n",
      "RMSE for training: 0.9658089218593575\n",
      "RMSE for testing: 1.0333990846198864\n",
      "0.9914873414227512\n",
      "RMSE for training: 0.9656224005614347\n",
      "RMSE for testing: 1.0334294450247554\n",
      "0.9920393945081759\n",
      "RMSE for training: 0.9657251066747987\n",
      "RMSE for testing: 1.0333439464794418\n",
      "0.9925914475936006\n",
      "RMSE for training: 0.965605401877604\n",
      "RMSE for testing: 1.0334608475107057\n",
      "0.9931435006790253\n",
      "RMSE for training: 0.9523683050497077\n",
      "RMSE for testing: 1.0178383757328073\n",
      "0.99369555376445\n",
      "RMSE for training: 0.9523716185824571\n",
      "RMSE for testing: 1.0180448233397743\n",
      "0.9942476068498747\n",
      "RMSE for training: 0.9523443631405091\n",
      "RMSE for testing: 1.019502065909222\n",
      "0.9947996599352994\n",
      "RMSE for training: 0.9441631623277582\n",
      "RMSE for testing: 1.0057304733424912\n",
      "0.9953517130207241\n",
      "RMSE for training: 0.9438890793722519\n",
      "RMSE for testing: 1.005936898523354\n",
      "0.9959037661061487\n",
      "RMSE for training: 0.9395750046139999\n",
      "RMSE for testing: 0.9973895358018964\n",
      "0.9964558191915734\n",
      "RMSE for training: 0.9325937246817116\n",
      "RMSE for testing: 0.9906168814545085\n",
      "0.9970078722769982\n",
      "RMSE for training: 0.9328015936686994\n",
      "RMSE for testing: 0.9912678585701982\n",
      "0.9975599253624229\n",
      "RMSE for training: 0.9240348079475683\n",
      "RMSE for testing: 0.9736469135850676\n",
      "0.9981119784478475\n",
      "RMSE for training: 0.9242177534036861\n",
      "RMSE for testing: 0.9721003288107424\n",
      "0.9986640315332722\n",
      "RMSE for training: 0.9128866915968481\n",
      "RMSE for testing: 0.9647493466712667\n",
      "0.9992160846186969\n",
      "RMSE for training: 0.9127373640727998\n",
      "RMSE for testing: 0.9646111016507237\n",
      "0.9997681377041217\n",
      "RMSE for training: 0.9124674121331777\n",
      "RMSE for testing: 0.9657659986868574\n"
     ]
    }
   ],
   "source": [
    "train_errors, val_errors = [], []\n",
    "for m in range(70000, len(rate_train) + 1,50):\n",
    "    rs = MF(rate_train[:m,:], K = 50, lam = .01, print_every = 100, learning_rate = 50,max_iter = 30)\n",
    "    rs.fit()\n",
    "    print(m/(len(rate_train) + 1))\n",
    "    print('RMSE for training:', rs.evaluate_RMSE(rate_train))\n",
    "    print('RMSE for testing:', rs.evaluate_RMSE(rate_test))\n",
    "    train_errors.append(rs.evaluate_RMSE(rate_train))\n",
    "    val_errors.append(rs.evaluate_RMSE(rate_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save array of error to json file\n",
    "# with open(\"tra_md\", \"w\") as fp:\n",
    "#     json.dump(train_errors, fp)\n",
    "# with open(\"val_md\", \"w\") as fp:\n",
    "#     json.dump(val_errors, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err, val_err = [], []\n",
    "with open(\"tra_md\", \"r\") as fp:\n",
    "    train_err = json.load(fp)\n",
    "with open(\"val_md\", \"r\") as fp:\n",
    "    val_err = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "step = list(range(70000,90570,50))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(step,np.asarray(train_err), \"r-+\", linewidth=2, label=\"train\")\n",
    "plt.plot(step,np.asarray(val_err), \"b-\", linewidth=3, label=\"val\")\n",
    "plt.legend(loc=\"upper right\", fontsize=14)\n",
    "plt.xlabel(\"Training set size\", fontsize=14)\n",
    "plt.ylabel(\"RMSE\", fontsize=14)\n",
    "plt.axis([70000, 90570, 0.9, 2.1])\n",
    "plt.yticks(np.arange(min(np.asarray(train_err)), max(np.asarray(val_err)), 0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90570, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_test.shape\n",
    "rate_train.shape\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6d01fb95f95024a48e1a45fe820a33330a3d329b2755219bbba00e53c7554d7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ev_3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
