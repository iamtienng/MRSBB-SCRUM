{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from numpy import loadtxt,savetxt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratings with Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "ratings_base = pd.read_csv('./ml-1m/ratings.dat',sep='::', names=r_cols,engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>956716541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>956704887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>956704746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>956715648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>956715569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  movieId  rating  timestamp\n",
       "0             1     1193       5  978300760\n",
       "1             1      661       3  978302109\n",
       "2             1      914       3  978301968\n",
       "3             1     3408       4  978300275\n",
       "4             1     2355       5  978824291\n",
       "...         ...      ...     ...        ...\n",
       "1000204    6040     1091       1  956716541\n",
       "1000205    6040     1094       5  956704887\n",
       "1000206    6040      562       5  956704746\n",
       "1000207    6040     1096       4  956715648\n",
       "1000208    6040     1097       4  956715569\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_base['timestamp'] = pd.to_datetime(ratings_base['timestamp'],unit='s').apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:12:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 22:35:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 22:32:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>2001-01-06 23:38:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-04-26 02:35:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-04-25 23:21:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-04-25 23:19:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-04-26 02:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-04-26 02:19:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  movieId  rating            timestamp\n",
       "0             1     1193       5  2000-12-31 22:12:40\n",
       "1             1      661       3  2000-12-31 22:35:09\n",
       "2             1      914       3  2000-12-31 22:32:48\n",
       "3             1     3408       4  2000-12-31 22:04:35\n",
       "4             1     2355       5  2001-01-06 23:38:11\n",
       "...         ...      ...     ...                  ...\n",
       "1000204    6040     1091       1  2000-04-26 02:35:41\n",
       "1000205    6040     1094       5  2000-04-25 23:21:27\n",
       "1000206    6040      562       5  2000-04-25 23:19:06\n",
       "1000207    6040     1096       4  2000-04-26 02:20:48\n",
       "1000208    6040     1097       4  2000-04-26 02:19:29\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_base = np.asmatrix(ratings_base)\n",
    "for i in range(ratings_base.shape[0]):\n",
    "    if ratings_base[i,3] != '1970-01-01 00:00:00':\n",
    "        ratings_base[i,3] = '1970-01-01 00:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_base = pd.DataFrame(ratings_base, columns = ['userId', 'movieId', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_base.to_csv(r'./data/ratings.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies with Posters\n",
    "https://github.com/babu-thomas/movielens-posters/issues/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('movies.dat', delimiter=',', header=None, \n",
    "    names=['movie_id', 'title', 'genre'], engine='python')\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    movie_id = row['movie_id']\n",
    "    movie_title = row['title']\n",
    "    domain = 'http://www.imdb.com'\n",
    "    search_url = domain + '/find?q=' + urllib.parse.quote_plus(movie_title)\n",
    "    if movie_id <= 2347:\n",
    "        pass\n",
    "    with urllib.request.urlopen(search_url) as response:\n",
    "        html = response.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # Get url of 1st search result\n",
    "        try:\n",
    "            title = soup.find('table', class_='findList').tr.a['href']\n",
    "            movie_url = domain + title\n",
    "            with open('movie_url.csv', 'a', newline='') as out_csv:\n",
    "                writer = csv.writer(out_csv, delimiter=',')\n",
    "                writer.writerow([movie_id, movie_url])\n",
    "        # Ignore cases where search returns no results\n",
    "        except AttributeError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print('start', start)\n",
    "row_names = ['movie_id', 'movie_url']\n",
    "with open('movie_url.csv', 'r', newline='') as in_csv:\n",
    "    reader = csv.DictReader(in_csv, fieldnames=row_names, delimiter=',')\n",
    "\n",
    "    for row in reader:\n",
    "        movie_id = row['movie_id']\n",
    "        movie_url = row['movie_url']\n",
    "        domain = 'http://www.imdb.com'\n",
    "\n",
    "        with urllib.request.urlopen(movie_url) as response:\n",
    "            html = response.read()\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            # Get url of poster image\n",
    "            try:\n",
    "                image_url = soup.find('div', class_='poster').a.img['src']\n",
    "                extension = image_url[-4:]\n",
    "                image_url = ''.join(image_url.partition('_')[0]) + extension\n",
    "                filename = 'img/' + movie_id + extension\n",
    "                with urllib.request.urlopen(image_url) as response:\n",
    "                    with open('movie_poster.csv', 'a', newline='') as out_csv:\n",
    "                        writer = csv.writer(out_csv, delimiter=',')\n",
    "                        writer.writerow([movie_id, image_url])\n",
    "            # Ignore cases where no poster image is present\n",
    "            except AttributeError:\n",
    "                pass\n",
    "        print('movie_id:', movie_id)\n",
    "print('time:', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cols = ['movie id', 'movie title', 'movie genre']\n",
    "movies = pd.read_csv('ml-1m\\movies.dat', sep='::', names=i_cols, encoding='latin-1')\n",
    "movies = np.asmatrix(movies)\n",
    "movies = np.append(movies, np.zeros(movies.shape[0]).reshape(3883,1), axis=1)\n",
    "moviePosters = pd.read_csv('movie_poster.csv', sep=',', names=[\"1\",\"2\"], encoding='latin-1')\n",
    "moviePosters = np.asmatrix(moviePosters)\n",
    "for i in range(movies.shape[0]):\n",
    "    for j in range(moviePosters.shape[0]):\n",
    "        if movies[i,0] == moviePosters[j,0]:\n",
    "            movies[i,3] = moviePosters[j,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['movieId', 'movieTitle', 'movieGenre', 'moviePoster']\n",
    "movies = pd.read_csv('movies.csv',sep=',', names=r_cols,engine='python')\n",
    "movies = np.asmatrix(movies)\n",
    "for i in range(movies.shape[0]):\n",
    "    if ', The ' in movies[i,1]:\n",
    "        indexComma = movies[i,1].index(', The')\n",
    "        movies[i,1] = movies[i,1][indexComma+2:indexComma+5] +\" \"+ movies[i,1][0:indexComma]+\" \" + movies[i,1][indexComma+6:]\n",
    "for i in range(movies.shape[0]):\n",
    "    if ', An ' in movies[i,1]:\n",
    "        indexComma = movies[i,1].index(', An')\n",
    "        movies[i,1] = movies[i,1][indexComma+2:indexComma+4] +\" \"+ movies[i,1][0:indexComma]+\" \" + movies[i,1][indexComma+5:]\n",
    "for i in range(movies.shape[0]):\n",
    "    if ', A ' in movies[i,1]:\n",
    "        indexComma = movies[i,1].index(', A ')\n",
    "        movies[i,1] = movies[i,1][indexComma+2:indexComma+3] +\" \"+ movies[i,1][0:indexComma]+\" \" + movies[i,1][indexComma+4:]\n",
    "moviesPD = pd.DataFrame(movies)\n",
    "moviesPD.to_csv(r'moviesWithPosters.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['movieId', 'movieTitle', 'movieGenre', 'moviePoster']\n",
    "movies = pd.read_csv('moviesWithPosters.csv',sep=',', names=r_cols,engine='python')\n",
    "movies.to_csv(r'indexmoviesWithPosters.csv', index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to CSV MFCF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(object):\n",
    "    def __init__(self, Y, K, lam = 0.1, Xinit = None, Winit = None, \n",
    "    learning_rate = 0.5, max_iter = 10000, print_every = 100):\n",
    "        self.Y = Y      # represents the utility matrix\n",
    "        self.K = K      # number of features\n",
    "        self.lam = lam  # regularization parameter\n",
    "        self.learning_rate = learning_rate  # for gradient descent\n",
    "        self.max_iter = max_iter            # maximum number of iterations\n",
    "        self.print_every = print_every      # print loss after each a few iters\n",
    "        self.n_users = int(np.max(Y[:, 0])) + 1\n",
    "        self.users_ids = np.unique(np.asarray(Y[:,0].reshape(Y[:,0].shape[0]))).astype(np.int32)\n",
    "        self.n_items = int(np.max(Y[:, 1])) + 1\n",
    "        self.items_ids = np.unique(np.asarray(Y[:,1].reshape(Y[:,1].shape[0]))).astype(np.int32)\n",
    "        self.n_ratings = Y.shape[0]\n",
    "        self.X = np.random.randn(self.n_items, K) if Xinit is None else Xinit\n",
    "        self.W = np.random.randn(K, self.n_users) if Winit is None else Winit\n",
    "        self.b = np.random.randn(self.n_items)  # item biases\n",
    "        self.d = np.random.randn(self.n_users)  # user biases\n",
    "\n",
    "    # return current loss value\n",
    "    def loss(self):\n",
    "        L = 0\n",
    "        for i in range(self.n_ratings):\n",
    "            # user_id, item_id, rating\n",
    "            n, m, rating = int(self.Y[i, 0]), int(self.Y[i, 1]), self.Y[i, 2]\n",
    "            L += 0.5*(self.X[m].dot(self.W[:,n]) + self.b[m] + self.d[n] - rating)**2\n",
    "        L /= self.n_ratings\n",
    "        # regularization, don't ever forget this\n",
    "        return L + 0.5*self.lam*(np.sum(self.X**2) + np.sum(self.W**2))\n",
    "    \n",
    "    def updateXb(self):\n",
    "        for m in self.items_ids:\n",
    "            ids = np.where(self.Y[:, 1] == m)[0] # row indices of items m\n",
    "            user_ids, ratings = self.Y[ids, 0].astype(np.int32), self.Y[ids, 2]\n",
    "            Wm, dm = self.W[:, user_ids], self.d[user_ids]\n",
    "            Wm = Wm.reshape(Wm.shape[0], Wm.shape[1])\n",
    "            for i in range(30): # 30 iteration for each sub problem\n",
    "                xm = self.X[m]\n",
    "                error = Wm.T.dot(xm).reshape(-1,1) + self.b[m] + dm - ratings\n",
    "                grad_xm = Wm.dot(error)/self.n_ratings + (self.lam*xm).reshape(-1,1)\n",
    "                grad_bm = np.sum(error)/self.n_ratings\n",
    "                # gradient descent\n",
    "                self.X[m] -= np.array((self.learning_rate*grad_xm).T)[0]\n",
    "                self.b[m] -= self.learning_rate*grad_bm\n",
    "\n",
    "    def updateWd(self):\n",
    "        for n in self.users_ids:\n",
    "            # get all items rated by user n, and the corresponding ratings\n",
    "            ids = np.where(self.Y[:, 0] == n)[0]\n",
    "            item_ids, ratings = self.Y[ids, 1].astype(np.int32), self.Y[ids, 2]\n",
    "            Xn, bn = self.X[item_ids], self.b[item_ids]\n",
    "            for i in range(30): # 30 iteration for each sub problem\n",
    "                wn = self.W[:, n]\n",
    "                error = Xn.dot(wn) + bn + self.d[n] - ratings\n",
    "                grad_wn = Xn.T.dot(error)/self.n_ratings + self.lam*wn\n",
    "                grad_dn = np.sum(error)/self.n_ratings\n",
    "                # gradient descent\n",
    "                self.W[:, n] -= np.array(self.learning_rate*grad_wn.reshape(-1))[0]\n",
    "                self.d[n]    -= self.learning_rate*grad_dn\n",
    "\n",
    "    def updateXbItemI(self, itemID):\n",
    "        m = itemID\n",
    "        ids = np.where(self.Y[:, 1] == m)[0] # row indices of items m\n",
    "        user_ids, ratings = self.Y[ids, 0].astype(np.int32), self.Y[ids, 2]\n",
    "        Wm, dm = self.W[:, user_ids], self.d[user_ids]\n",
    "        Wm = Wm.reshape(Wm.shape[0], Wm.shape[1])\n",
    "        for i in range(30): # 30 iteration for each sub problem\n",
    "            xm = self.X[m]\n",
    "            error = Wm.T.dot(xm).reshape(-1,1) + self.b[m] + dm - ratings\n",
    "            grad_xm = Wm.dot(error)/self.n_ratings + (self.lam*xm).reshape(-1,1)\n",
    "            grad_bm = np.sum(error)/self.n_ratings\n",
    "            # gradient descent\n",
    "            self.X[m] -= np.array((self.learning_rate*grad_xm).T)[0]\n",
    "            self.b[m] -= self.learning_rate*grad_bm\n",
    "\n",
    "    def updateWdUserU(self, userID):\n",
    "        n = userID\n",
    "        # get all items rated by user n, and the corresponding ratings\n",
    "        ids = np.where(self.Y[:, 0] == n)[0]\n",
    "        item_ids, ratings = self.Y[ids, 1].astype(np.int32), self.Y[ids, 2]\n",
    "        Xn, bn = self.X[item_ids], self.b[item_ids]\n",
    "        for i in range(30): # 30 iteration for each sub problem\n",
    "            wn = self.W[:, n]\n",
    "            error = Xn.dot(wn) + bn + self.d[n] - ratings\n",
    "            grad_wn = Xn.T.dot(error)/self.n_ratings + self.lam*wn\n",
    "            grad_dn = np.sum(error)/self.n_ratings\n",
    "            # gradient descent\n",
    "            self.W[:, n] -= np.array(self.learning_rate*grad_wn.reshape(-1))[0]\n",
    "            self.d[n]    -= self.learning_rate*grad_dn\n",
    "\n",
    "    def fit(self):\n",
    "        for it in range(self.max_iter):\n",
    "            self.updateXb()\n",
    "            self.updateWd()\n",
    "            # if (it+1) % self.print_every == 0:\n",
    "            #     rsme_train = self.evaluate_RMSE(self.Y)\n",
    "            #     # print(\"iter = \",it+1 ,\", loss = \"+self.loss(),\", RMSE train = \",rsme_train)\n",
    "            #     print(it+1)\n",
    "            #     print(self.loss())\n",
    "            #     print(rsme_train)\n",
    "            #     print(self.evaluate_RMSE(rate_test))\n",
    "\n",
    "    def pred(self, u, i):\n",
    "        # predict the rating of user u for item i\n",
    "        u, i = int(u), int(i)\n",
    "        try:\n",
    "            pred = self.X[i, :].dot(self.W[:, u]) + self.b[i] + self.d[u]\n",
    "        except:\n",
    "            return 0\n",
    "        return max(0, min(5, pred))\n",
    "\n",
    "    def evaluate_RMSE(self, rate_test):\n",
    "        n_tests = rate_test.shape[0]\n",
    "        SE = 0\n",
    "        for n in range(n_tests):\n",
    "            pred = self.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "            SE += (pred - rate_test[n, 2])**2\n",
    "        \n",
    "        RMSE = np.sqrt(SE/n_tests)\n",
    "        return RMSE\n",
    "    \n",
    "    def predTopTen(self, user_id):\n",
    "        # predict the top 10 items for user user_id\n",
    "        items_ids = np.unique(np.asarray(self.Y[:,1].reshape(self.Y[:,1].shape[0]))).astype(np.int32)\n",
    "        ids = np.where(self.Y[:, 0] == user_id)[0]\n",
    "        rated_item_ids = self.Y[ids, 1].astype(np.int32)\n",
    "        unrated_item_ids = [x for x in items_ids if x not in rated_item_ids]\n",
    "        items_ids = unrated_item_ids\n",
    "        predForUserU = np.random.randn(len(items_ids), 2)\n",
    "        for i in range(len(items_ids)):\n",
    "            predForUserU[i] = [items_ids[i],self.pred(u= user_id,i = i)]\n",
    "        predForUserU= predForUserU[predForUserU[:,1].argsort()][::-1]\n",
    "        idsTopTen = predForUserU[:10,0].astype(np.int32).tolist()\n",
    "        ratingsTopTen = predForUserU[:10,1].tolist()\n",
    "        return(idsTopTen,ratingsTopTen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cols = ['userIdd', 'movieId', 'rating','timestamp']\n",
    "ratings = pd.read_csv('./ml-1m/ratings.dat', sep='::', names=i_cols, encoding='latin-1', engine='python')\n",
    "ratings_matrix = rate_train = np.asmatrix(ratings)\n",
    "ratings_matrix[:, :2] -= 1\n",
    "rate_train, rate_test = train_test_split(ratings_matrix, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9217762262677203"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = MF(rate_train, K = 50, lam = .01, print_every = 1, learning_rate = 50,max_iter = 30)\n",
    "# rs.fit()\n",
    "# To load X W b d\n",
    "XX = loadtxt('./model/XX.csv', delimiter=',')\n",
    "WW = loadtxt('./model/WW.csv', delimiter=',')\n",
    "bb = loadtxt('./model/bb.csv', delimiter=',')\n",
    "dd = loadtxt('./model/dd.csv', delimiter=',')\n",
    "rs.X = XX\n",
    "rs.W = WW\n",
    "rs.b = bb\n",
    "rs.d = dd\n",
    "rs.evaluate_RMSE(rate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save X W b d\n",
    "# XX = rs.X\n",
    "# WW = rs.W.T\n",
    "# bb = rs.b\n",
    "# dd = rs.d\n",
    "# savetxt('XX.csv', XX, delimiter=',')\n",
    "# savetxt('WW.csv', WW, delimiter=',')\n",
    "# savetxt('bb.csv', bb, delimiter=',')\n",
    "# savetxt('dd.csv', dd, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "XXI = pd.DataFrame(XX, columns = ['e1','e2','e3','e4','e5','e6','e7','e8','e9','e10','e11','e12','e13','e14','e15','e16','e17','e18','e19','e20','e21','e22','e23','e24','e25','e26','e27','e28','e29','e30','e31','e32','e33','e34','e35','e36','e37','e38','e39','e40','e41','e42','e43','e44','e45','e46','e47','e48','e49','e50'])\n",
    "WWI = pd.DataFrame(WW.T, columns = ['e1','e2','e3','e4','e5','e6','e7','e8','e9','e10','e11','e12','e13','e14','e15','e16','e17','e18','e19','e20','e21','e22','e23','e24','e25','e26','e27','e28','e29','e30','e31','e32','e33','e34','e35','e36','e37','e38','e39','e40','e41','e42','e43','e44','e45','e46','e47','e48','e49','e50'])\n",
    "bbI = pd.DataFrame(bb, columns = ['e1'])\n",
    "ddI = pd.DataFrame(dd, columns = ['e1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "XXI.to_csv(r'./data/XXI.csv', index=True)\n",
    "WWI.to_csv(r'./data/WWI.csv', index=True)\n",
    "bbI.to_csv(r'./data/bbI.csv', index=True)\n",
    "ddI.to_csv(r'./data/ddI.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a4eb5f4c79d4e05c63481b3df8f15c06ab8b0cd9d0505c5d1727c45c974d525"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
